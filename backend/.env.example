# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
MODEL_NAME=tinyllama

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=True

# Optional: You can add these if needed
# LOG_LEVEL=INFO
# MAX_UPLOAD_SIZE=10485760  # 10MB